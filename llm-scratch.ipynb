{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1da733-7d5b-4c6a-815b-344dcc627a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "\n",
    "os.environ['HF_HOME']='/srv/starter_content/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5cfa3a4-ed7a-461a-a335-09cfeafc2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Trendyol/Trendyol-LLM-7b-chat-v0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d7dbf-fc29-4cc4-a9a0-50ade36ba1b3",
   "metadata": {},
   "source": [
    "## NDP LLM Service Documentation\n",
    "\n",
    "This Python code snippet is designed to launch various components of a chat service named \"FastChat.\" Each function starts a different part of the service using the `subprocess.run` method to execute shell commands.\n",
    "\n",
    "### `run_controller()`\n",
    "\n",
    "Starts the controller for the FastChat service, responsible for managing and coordinating different parts of the service.\n",
    "\n",
    "```python\n",
    "def run_controller():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.controller\", \"--host\", \"127.0.0.1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2153eb97-e79f-4592-8a49-5ce4ff1efe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_controller():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.controller\", \"--host\", \"127.0.0.1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3730d1d8-8a13-4b7c-907c-03b948f6633b",
   "metadata": {},
   "source": [
    "## `run_worker`\n",
    "Initiates a model worker for processing and generating responses based on specified models. Runs the model worker module, specifying the local host and a list of model names for processing requests. The --model-path argument should point to the directory where the models are stored.\n",
    "```python \n",
    "def run_model_worker():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.model_worker\", \"--host\", \"127.0.0.1\", \"--model-names\", \"gpt-4-turbo,Trendyol-LLM-7b-chat-v0.1,text-embedding-ada-002\", \"--model-path\", model])\n",
    "\n",
    "```\n",
    "### `run_api`\n",
    "\n",
    "Launches an API server that handles API requests to the FastChat service.\n",
    "Runs the API server module on the local host, acting as an interface between the service and external clients or applications.\n",
    "```python\n",
    "def run_api_server():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.openai_api_server\", \"--host\", \"127.0.0.1\"])\n",
    "```    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3879fbbe-fdfc-42a4-b4ed-cbab96c2a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_worker():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.model_worker\", \"--host\", \"127.0.0.1\", \"--model-names\", \"gpt-3.5-turbo,Trendyol-LLM-7b-chat-v0.1,text-embedding-ada-002\", \"--model-path\", model])\n",
    "\n",
    "def run_api_server():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.openai_api_server\", \"--host\", \"127.0.0.1\"])\n",
    "def run_ui_server():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.gradio_web_server\", \"--host\", \"127.0.0.1\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a7ae9-3ab4-460c-baf2-80a0ae43a45a",
   "metadata": {},
   "source": [
    "## Starting the `run_controller` Function in a Separate Thread\n",
    "\n",
    "To enable the FastChat controller to run concurrently with the main program, the `run_controller` function is executed in a separate thread. This is achieved using Python's `threading` module, which allows for the execution of code in parallel to the main execution flow of the program.\n",
    "\n",
    "### Code Snippet:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "controller_thread = threading.Thread(target=run_controller)\n",
    "controller_thread.start()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9629becb-dfcd-4262-be6c-d3606e711ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:25:31 | INFO | controller | args: Namespace(host='127.0.0.1', port=21001, dispatch_method='shortest_queue', ssl=False)\n",
      "2024-03-05 00:25:31 | ERROR | stderr | INFO:     Started server process [4337]\n",
      "2024-03-05 00:25:31 | ERROR | stderr | INFO:     Waiting for application startup.\n",
      "2024-03-05 00:25:31 | ERROR | stderr | INFO:     Application startup complete.\n",
      "2024-03-05 00:25:31 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:21001 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "controller_thread = threading.Thread(target=run_controller)\n",
    "controller_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789765a-af59-4fc7-80a7-06b32114b829",
   "metadata": {},
   "source": [
    "## Starting the `run_model_worker` Function in a Separate Thread\n",
    "\n",
    "To facilitate concurrent execution of the FastChat model worker alongside the main program and potentially other service components, the `run_model_worker` function is executed in a separate thread. This concurrent execution is made possible through the use of Python's `threading` module.\n",
    "\n",
    "### Code Snippet:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "model_worker_thread = threading.Thread(target=run_model_worker)\n",
    "model_worker_thread.start()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b3ac13-42c2-4420-a4cd-476cf633b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain openai chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a4eab9-b566-4230-8c5f-8fd73d6a8b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:26:25 | INFO | model_worker | args: Namespace(host='127.0.0.1', port=21002, worker_address='http://localhost:21002', controller_address='http://localhost:21001', model_path='Trendyol/Trendyol-LLM-7b-chat-v0.1', revision='main', device='cuda', gpus=None, num_gpus=1, max_gpu_memory=None, dtype=None, load_8bit=False, cpu_offloading=False, gptq_ckpt=None, gptq_wbits=16, gptq_groupsize=-1, gptq_act_order=False, awq_ckpt=None, awq_wbits=16, awq_groupsize=-1, enable_exllama=False, exllama_max_seq_len=4096, exllama_gpu_split=None, exllama_cache_8bit=False, enable_xft=False, xft_max_seq_len=4096, xft_dtype=None, model_names=['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'], conv_template=None, embed_in_truncate=False, limit_worker_concurrency=5, stream_interval=2, no_register=False, seed=None, debug=False, ssl=False)\n",
      "2024-03-05 00:26:25 | INFO | model_worker | Loading the model ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'] on worker de683719 ...\n",
      "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:10,  2.16s/it]\n",
      "Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:08,  2.21s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 3/6 [00:06<00:06,  2.24s/it]\n",
      "Loading checkpoint shards:  67%|██████▋   | 4/6 [00:09<00:04,  2.28s/it]\n",
      "Loading checkpoint shards:  83%|████████▎ | 5/6 [00:12<00:02,  2.66s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:13<00:00,  2.13s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:13<00:00,  2.24s/it]\n",
      "2024-03-05 00:26:39 | ERROR | stderr | \n",
      "2024-03-05 00:26:43 | INFO | model_worker | Register to controller\n",
      "2024-03-05 00:26:43 | INFO | controller | Register a new worker: http://localhost:21002\n",
      "2024-03-05 00:26:43 | INFO | controller | Register done: http://localhost:21002, {'model_names': ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'], 'speed': 1, 'queue_length': 0}\n",
      "2024-03-05 00:26:43 | INFO | stdout | INFO:     127.0.0.1:49990 - \"POST /register_worker HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:26:44 | ERROR | stderr | INFO:     Started server process [4447]\n",
      "2024-03-05 00:26:44 | ERROR | stderr | INFO:     Waiting for application startup.\n",
      "2024-03-05 00:26:44 | ERROR | stderr | INFO:     Application startup complete.\n",
      "2024-03-05 00:26:44 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:21002 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "model_worker_thread = threading.Thread(target=run_model_worker)\n",
    "model_worker_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18fdd025-0d10-4b2a-94c5-a2fe681cf1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 20:20:09 | INFO | model_worker | args: Namespace(host='127.0.0.1', port=21002, worker_address='http://localhost:21002', controller_address='http://localhost:21001', model_path='Trendyol/Trendyol-LLM-7b-chat-v0.1', revision='main', device='cuda', gpus=None, num_gpus=1, max_gpu_memory=None, dtype=None, load_8bit=False, cpu_offloading=False, gptq_ckpt=None, gptq_wbits=16, gptq_groupsize=-1, gptq_act_order=False, awq_ckpt=None, awq_wbits=16, awq_groupsize=-1, enable_exllama=False, exllama_max_seq_len=4096, exllama_gpu_split=None, exllama_cache_8bit=False, enable_xft=False, xft_max_seq_len=4096, xft_dtype=None, model_names=['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'], conv_template=None, embed_in_truncate=False, limit_worker_concurrency=5, stream_interval=2, no_register=False, seed=None, debug=False, ssl=False)\n",
      "2024-03-04 20:20:09 | INFO | model_worker | Loading the model ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'] on worker d4a93f36 ...\n",
      "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:10,  2.19s/it]\n",
      "Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:09,  2.28s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:09,  3.02s/it]\n",
      "Loading checkpoint shards:  67%|██████▋   | 4/6 [00:13<00:08,  4.00s/it]\n",
      "Loading checkpoint shards:  83%|████████▎ | 5/6 [00:16<00:03,  3.42s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:17<00:00,  2.63s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:17<00:00,  2.90s/it]\n",
      "2024-03-04 20:20:28 | ERROR | stderr | \n",
      "2024-03-04 20:20:33 | INFO | model_worker | Register to controller\n",
      "2024-03-04 20:20:33 | INFO | controller | Register a new worker: http://localhost:21002\n",
      "2024-03-04 20:20:33 | INFO | controller | Register done: http://localhost:21002, {'model_names': ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'], 'speed': 1, 'queue_length': 0}\n",
      "2024-03-04 20:20:33 | INFO | stdout | INFO:     127.0.0.1:38320 - \"POST /register_worker HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:20:33 | ERROR | stderr | INFO:     Started server process [3186]\n",
      "2024-03-04 20:20:33 | ERROR | stderr | INFO:     Waiting for application startup.\n",
      "2024-03-04 20:20:33 | ERROR | stderr | INFO:     Application startup complete.\n",
      "2024-03-04 20:20:33 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:21002 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec420dc4-bfb8-4a29-b34b-1bab4a203385",
   "metadata": {},
   "source": [
    "## Running the `run_api_server` Function in a Separate Thread\n",
    "\n",
    "To ensure the API server component of the FastChat service operates concurrently with other parts of the application, the `run_api_server` function is launched in a separate thread. This concurrency is achieved with the help of Python's `threading` module, allowing multiple components to run simultaneously, improving scalability and responsiveness.\n",
    "\n",
    "### Code Snippet:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "api_server_thread = threading.Thread(target=run_api_server)\n",
    "api_server_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997d6983-f16e-417e-b648-fc918917c93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:26:56 | INFO | openai_api_server | args: Namespace(host='127.0.0.1', port=8000, controller_address='http://localhost:21001', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_keys=None, ssl=False)\n",
      "2024-03-05 00:26:56 | ERROR | stderr | INFO:     Started server process [4675]\n",
      "2024-03-05 00:26:56 | ERROR | stderr | INFO:     Waiting for application startup.\n",
      "2024-03-05 00:26:56 | ERROR | stderr | INFO:     Application startup complete.\n",
      "2024-03-05 00:26:56 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
      "2024-03-05 00:27:29 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:27:29 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:27:29 | INFO | stdout | INFO:     127.0.0.1:35308 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:28:14 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:28:14 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:28:14 | INFO | stdout | INFO:     127.0.0.1:46554 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:28:50 | INFO | stdout | INFO:     127.0.0.1:45110 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:28:50 | INFO | stdout | INFO:     127.0.0.1:45110 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:28:58 | INFO | controller | Register a new worker: http://localhost:21002\n",
      "2024-03-05 00:28:58 | INFO | stdout | INFO:     127.0.0.1:33288 - \"POST /worker_get_status HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:28:58 | INFO | controller | Register done: http://localhost:21002, {'model_names': ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'], 'speed': 1, 'queue_length': 0}\n",
      "2024-03-05 00:28:58 | INFO | stdout | INFO:     127.0.0.1:34498 - \"POST /refresh_all_workers HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:28:58 | INFO | stdout | INFO:     127.0.0.1:34510 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:28:58 | INFO | stdout | INFO:     127.0.0.1:45118 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:28:59 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:28:59 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:28:59 | INFO | stdout | INFO:     127.0.0.1:34520 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:29:00 | INFO | controller | Register a new worker: http://localhost:21002\n",
      "2024-03-05 00:29:00 | INFO | stdout | INFO:     127.0.0.1:51414 - \"POST /worker_get_status HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:29:00 | INFO | controller | Register done: http://localhost:21002, {'model_names': ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'], 'speed': 1, 'queue_length': 0}\n",
      "2024-03-05 00:29:00 | INFO | stdout | INFO:     127.0.0.1:34326 - \"POST /refresh_all_workers HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:29:00 | INFO | stdout | INFO:     127.0.0.1:34336 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:29:00 | INFO | stdout | INFO:     127.0.0.1:45118 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:29:44 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:29:44 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:29:44 | INFO | stdout | INFO:     127.0.0.1:48528 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "api_server_thread = threading.Thread(target=run_api_server)\n",
    "api_server_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "889395f9-a7b1-413e-b67b-8f494abd5dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"list\",\"data\":[{\"id\":\"Trendyol-LLM-7b-chat-v0.1\",\"object\":\"model\",\"created\":1709598624,\"owned_by\":\"fastchat\",\"root\":\"Trendyol-LLM-7b-chat-v0.1\",\"parent\":null,\"permission\":[{\"id\":\"modelperm-b7PyASyzU9WuBLJjsaSogH\",\"object\":\"model_permission\",\"created\":1709598624,\"allow_create_engine\":false,\"allow_sampling\":true,\"allow_logprobs\":true,\"allow_search_indices\":true,\"allow_view\":true,\"allow_fine_tuning\":false,\"organization\":\"*\",\"group\":null,\"is_blocking\":false}]},{\"id\":\"gpt-3.5-turbo\",\"object\":\"model\",\"created\":1709598624,\"owned_by\":\"fastchat\",\"root\":\"gpt-3.5-turbo\",\"parent\":null,\"permission\":[{\"id\":\"modelperm-bo3dwMczyrpu4s4LUyYaNa\",\"object\":\"model_permission\",\"created\":1709598624,\"allow_create_engine\":false,\"allow_sampling\":true,\"allow_logprobs\":true,\"allow_search_indices\":true,\"allow_view\":true,\"allow_fine_tuning\":false,\"organization\":\"*\",\"group\":null,\"is_blocking\":false}]},{\"id\":\"text-embedding-ada-002\",\"object\":\"model\",\"created\":1709598624,\"owned_by\":\"fastchat\",\"root\":\"text-embedding-ada-002\",\"parent\":null,\"permission\":[{\"id\":\"modelperm-3JfZpRuhvgmhCjpohcpmU4\",\"object\":\"model_permission\",\"created\":1709598624,\"allow_create_engine\":false,\"allow_sampling\":true,\"allow_logprobs\":true,\"allow_search_indices\":true,\"allow_view\":true,\"allow_fine_tuning\":false,\"organization\":\"*\",\"group\":null,\"is_blocking\":false}]}]}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:30:24 | INFO | controller | Register a new worker: http://localhost:21002\n",
      "2024-03-05 00:30:24 | INFO | stdout | INFO:     127.0.0.1:40450 - \"POST /worker_get_status HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:30:24 | INFO | controller | Register done: http://localhost:21002, {'model_names': ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002'], 'speed': 1, 'queue_length': 0}\n",
      "2024-03-05 00:30:24 | INFO | stdout | INFO:     127.0.0.1:57632 - \"POST /refresh_all_workers HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:30:24 | INFO | stdout | INFO:     127.0.0.1:57640 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:30:24 | INFO | stdout | INFO:     127.0.0.1:58558 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:30:29 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:30:29 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:30:29 | INFO | stdout | INFO:     127.0.0.1:57646 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:31:14 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:31:14 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:31:14 | INFO | stdout | INFO:     127.0.0.1:54886 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:31:59 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:31:59 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:31:59 | INFO | stdout | INFO:     127.0.0.1:40398 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:32:44 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:32:44 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:32:44 | INFO | stdout | INFO:     127.0.0.1:52744 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:33:29 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: None. call_ct: 0. worker_id: de683719. \n",
      "2024-03-05 00:33:29 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:33:29 | INFO | stdout | INFO:     127.0.0.1:53924 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "!curl  -X 'GET' \\\n",
    "  'http://localhost:8000/v1/models' \\\n",
    "  -H 'accept: application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee017faf-39cc-40f4-8347-4c9e7b77b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:36:11 | INFO | stdout | INFO:     127.0.0.1:43408 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:36:11 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:36:11 | INFO | stdout | INFO:     127.0.0.1:43416 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:36:11 | INFO | stdout | INFO:     127.0.0.1:49722 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:36:11 | INFO | stdout | INFO:     127.0.0.1:49724 - \"POST /count_token HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:36:29 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=4, locked=False). call_ct: 3. worker_id: de683719. \n",
      "2024-03-05 00:36:29 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:36:29 | INFO | stdout | INFO:     127.0.0.1:37816 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-3vXgoUfUaiVj5VCpqXCcQC\",\"object\":\"chat.completion\",\"created\":1709598998,\"model\":\"Trendyol-LLM-7b-chat-v0.1\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Fumio Kishida is the current Prime Minister of Japan. He was elected to this position in November 2018 and is serving his second term. Kishida is a politician and former member of the Japanese Liberal Democratic Party (LDP). He has previously held various positions in government, including Minister of Finance, Minister of the Environment, and Minister of Economics, Trade and Industry.\\nKishida is known for promoting liberal economic policies, including higher taxes and higher government spending. He also advocates for greater social equity within Japan, particularly for low-income families. Kishida is often seen as a champion of Japan's renewal process, which aims to reconstruct the country's economy and society after the pandemic and the economic resiliency challenges faced in recent years.\\nBesides being Prime Minister, Kishida is also known as a strong advocate for nuclear energy and the re-operation of nuclear power plants in Japan. He believes that nuclear energy is an important tool for meeting Japan's energy needs in a cost-effective and environmentally-friendly way. Kishida has also advocated for international cooperation and diplomacy, particularly in Asia and the Pacific Rim region. He is committed to strengthening Japan's role in the global economy by fostering international trade and investment.\\nKishida is widely respected in Japan for his leadership skills, working-class beliefs, and commitment to creating a better future for his country. He is a dynamic and popular figure in Japanese politics and is often seen as a role model for young people in Japan. Kishida is also known for his personal interest in sports, particularly basketball and golf, and is considered a passionate supporter of team Japan in international tournaments.\\nIn conclusion, Fumio Kishida is a Japanese politician and the current Prime Minister of Japan. He has held various positions in government and is known for promoting liberal economic policies, advocating for social equity, and advocating for nuclear energy and international cooperation and diplomacy. He is also widely respected in Japan for his leadership skills, working-class beliefs, and commitment to creating a better future for his country.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":595,\"total_tokens\":1070,\"completion_tokens\":475}}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:36:38 | INFO | stdout | INFO:     127.0.0.1:49736 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:36:38 | INFO | stdout | INFO:     127.0.0.1:51494 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:37:14 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 3. worker_id: de683719. \n",
      "2024-03-05 00:37:14 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:37:14 | INFO | stdout | INFO:     127.0.0.1:50418 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:37:56 | INFO | stdout | INFO:     127.0.0.1:44870 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:37:56 | INFO | stdout | INFO:     127.0.0.1:46872 - \"POST /v1/embeddings?model_name=Trendyol-LLM-7b-chat-v0.1 HTTP/1.1\" 400 Bad Request\n",
      "2024-03-05 00:37:59 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 3. worker_id: de683719. \n",
      "2024-03-05 00:37:59 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:37:59 | INFO | stdout | INFO:     127.0.0.1:43214 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:38:40 | INFO | stdout | INFO:     127.0.0.1:37866 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:38:40 | INFO | stdout | INFO:     127.0.0.1:35446 - \"POST /v1/embeddings?model_name=Trendyol-LLM-7b-chat-v0.1%26%26text-embedding-ada-002%26%26gpt-3.5-turbo%20allowed%20now HTTP/1.1\" 400 Bad Request\n",
      "2024-03-05 00:38:44 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 3. worker_id: de683719. \n",
      "2024-03-05 00:38:44 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:38:44 | INFO | stdout | INFO:     127.0.0.1:37868 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:05 | INFO | stdout | INFO:     127.0.0.1:53128 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:05 | INFO | stdout | INFO:     127.0.0.1:45978 - \"POST /api/v1/chat/completions HTTP/1.1\" 400 Bad Request\n",
      "2024-03-05 00:39:07 | INFO | stdout | INFO:     127.0.0.1:53144 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:07 | INFO | stdout | INFO:     127.0.0.1:45978 - \"POST /api/v1/chat/completions HTTP/1.1\" 400 Bad Request\n",
      "2024-03-05 00:39:29 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 3. worker_id: de683719. \n",
      "2024-03-05 00:39:29 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:39:29 | INFO | stdout | INFO:     127.0.0.1:42696 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:33 | INFO | stdout | INFO:     127.0.0.1:42702 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:33 | INFO | stdout | INFO:     127.0.0.1:41862 - \"POST /api/v1/chat/completions HTTP/1.1\" 400 Bad Request\n",
      "2024-03-05 00:39:47 | INFO | stdout | INFO:     127.0.0.1:44610 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:47 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:39:47 | INFO | stdout | INFO:     127.0.0.1:44614 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:47 | INFO | stdout | INFO:     127.0.0.1:36918 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:47 | INFO | stdout | INFO:     127.0.0.1:36930 - \"POST /count_token HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:52 | INFO | stdout | INFO:     127.0.0.1:36936 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:39:52 | INFO | stdout | INFO:     127.0.0.1:52208 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:14 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 4. worker_id: de683719. \n",
      "2024-03-05 00:40:14 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:40:14 | INFO | stdout | INFO:     127.0.0.1:36194 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:14 | INFO | stdout | INFO:     127.0.0.1:36198 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:14 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:40:14 | INFO | stdout | INFO:     127.0.0.1:36208 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:14 | INFO | stdout | INFO:     127.0.0.1:41158 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:14 | INFO | stdout | INFO:     127.0.0.1:41162 - \"POST /count_token HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:17 | INFO | stdout | INFO:     127.0.0.1:41164 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:17 | INFO | stdout | INFO:     127.0.0.1:51138 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:35 | INFO | stdout | INFO:     127.0.0.1:53926 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:35 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [1.0], ret: http://localhost:21002\n",
      "2024-03-05 00:40:35 | INFO | stdout | INFO:     127.0.0.1:53942 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:35 | INFO | stdout | INFO:     127.0.0.1:60222 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:35 | INFO | stdout | INFO:     127.0.0.1:60234 - \"POST /count_token HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:39 | INFO | stdout | INFO:     127.0.0.1:60238 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:39 | INFO | stdout | INFO:     127.0.0.1:43814 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:40:59 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 6. worker_id: de683719. \n",
      "2024-03-05 00:40:59 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:40:59 | INFO | stdout | INFO:     127.0.0.1:47246 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:41:14 | INFO | stdout | INFO:     127.0.0.1:58568 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:41:14 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:41:14 | INFO | stdout | INFO:     127.0.0.1:58582 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:41:14 | INFO | stdout | INFO:     127.0.0.1:34050 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:41:14 | INFO | stdout | INFO:     127.0.0.1:34066 - \"POST /count_token HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:41:18 | INFO | stdout | INFO:     127.0.0.1:34078 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:41:18 | INFO | stdout | INFO:     127.0.0.1:50826 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:41:44 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 7. worker_id: de683719. \n",
      "2024-03-05 00:41:44 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:41:44 | INFO | stdout | INFO:     127.0.0.1:49384 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:42:29 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 7. worker_id: de683719. \n",
      "2024-03-05 00:42:29 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:42:29 | INFO | stdout | INFO:     127.0.0.1:53080 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:43:14 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 7. worker_id: de683719. \n",
      "2024-03-05 00:43:14 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:43:14 | INFO | stdout | INFO:     127.0.0.1:51732 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:8000/v1/chat/completions  -H \"Content-Type: application/json\"  -d '{ \"model\": \"Trendyol-LLM-7b-chat-v0.1\", \"messages\": [{\"role\": \"user\", \"content\": \"Who is Fumio Kishida?\"}]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e066f108-e7fd-4d29-b080-e8b3b654aee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:43:56 | INFO | stdout | INFO:     127.0.0.1:59382 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:43:56 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:43:56 | INFO | stdout | INFO:     127.0.0.1:59396 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:43:56 | INFO | stdout | INFO:     127.0.0.1:53230 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:43:56 | INFO | stdout | INFO:     127.0.0.1:53246 - \"POST /count_token HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:43:59 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=4, locked=False). call_ct: 8. worker_id: de683719. \n",
      "2024-03-05 00:43:59 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:43:59 | INFO | stdout | INFO:     127.0.0.1:39090 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-xFbxx6rVgGWWGXH5LKu4Rn\",\"object\":\"chat.completion\",\"created\":1709599449,\"model\":\"Trendyol-LLM-7b-chat-v0.1\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Fumio Kishida is a Japanese politician and former Prime Minister of Japan. He served as Prime Minister for two terms, from 2011 to 2016. Kishida, born in Nagoya, Japonya, was elected to the House of Representatives in 1999 and served there as a member until he became Prime Minister. As Prime Minister, Kishida was known for his focus on national unity, promoting social stability, and maintaining a strong economy. He was also known for his efforts to improve Japan's nuclear energy program. Kishida is a grandson of the late Japanese Prime Minister Yoshihide Suga who served in the late 1950s and early 1960s. Kishida, who speaks fluent English, has held various positions in leadership and public service, such as Minister of Internal Affairs (2005-2008) and Chairman of the Democratic Party (2006-2008). He is currently serving as the Chairman of the Japanese Democratic Party. Kishida is considered a promising leader in Japan and is widely respected for his commitment to serving his country.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":595,\"total_tokens\":827,\"completion_tokens\":232}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:44:09 | INFO | stdout | INFO:     127.0.0.1:53250 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:44:09 | INFO | stdout | INFO:     127.0.0.1:43186 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:44:44 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 8. worker_id: de683719. \n",
      "2024-03-05 00:44:44 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:44:44 | INFO | stdout | INFO:     127.0.0.1:56742 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:45:30 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 8. worker_id: de683719. \n",
      "2024-03-05 00:45:30 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:45:30 | INFO | stdout | INFO:     127.0.0.1:44804 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"Trendyol-LLM-7b-chat-v0.1\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Who is Fumio Kishida?\"}],\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "952c4d98-8b10-40b6-869b-af634dc18e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:52:09 | INFO | stdout | INFO:     127.0.0.1:40834 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:09 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:52:09 | INFO | stdout | INFO:     127.0.0.1:40848 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:09 | INFO | stdout | INFO:     127.0.0.1:57856 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:09 | INFO | stdout | INFO:     127.0.0.1:57862 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-4SVmw7mPZM8PQCgkyWSF2a\",\"object\":\"chat.completion\",\"created\":1709599930,\"model\":\"Trendyol-LLM-7b-chat-v0.1\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"\\nBurada, Ketanji Brown Jackson hakkında ABD Başkanı Joe Biden'ın ne söylediğini öğrenin.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":14,\"total_tokens\":40,\"completion_tokens\":26}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:52:10 | INFO | stdout | INFO:     127.0.0.1:57868 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:10 | INFO | stdout | INFO:     127.0.0.1:54680 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:15 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 19. worker_id: de683719. \n",
      "2024-03-05 00:52:15 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:52:15 | INFO | stdout | INFO:     127.0.0.1:59794 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:48 | INFO | stdout | INFO:     127.0.0.1:57768 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:48 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:52:48 | INFO | stdout | INFO:     127.0.0.1:57774 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:48 | INFO | stdout | INFO:     127.0.0.1:47294 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:48 | INFO | stdout | INFO:     127.0.0.1:47308 - \"POST /count_token HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:51 | INFO | stdout | INFO:     127.0.0.1:47324 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:52:51 | INFO | stdout | INFO:     127.0.0.1:55158 - \"POST /api/v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:53:00 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 20. worker_id: de683719. \n",
      "2024-03-05 00:53:00 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:53:00 | INFO | stdout | INFO:     127.0.0.1:41968 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:53:45 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 20. worker_id: de683719. \n",
      "2024-03-05 00:53:45 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:53:45 | INFO | stdout | INFO:     127.0.0.1:40034 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/api/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"Trendyol-LLM-7b-chat-v0.1\",\n",
    "    \"messages\": \"What did the president say about Ketanji Brown Jackson?\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": -1,\n",
    "    \"n\": 1,\n",
    "    \"max_tokens\": 650,\n",
    "    \"stop\": \"string\",\n",
    "    \"stream\": False,\n",
    "    \"user\": \"string\",\n",
    "    \"repetition_penalty\": 1,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58eee5d3-fc28-40f6-b7b4-bd42a19beeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_BASE'] = 'http://localhost:8000/v1'\n",
    "os.environ['OPENAI_API_KEY'] = 'EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5404200-fdea-4ea1-bf27-7b6feb15d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 19:52:15--  https://raw.githubusercontent.com/hwchase17/langchain/v0.0.200/docs/modules/state_of_the_union.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39027 (38K) [text/plain]\n",
      "Saving to: ‘state_of_the_union.txt.1’\n",
      "\n",
      "state_of_the_union. 100%[===================>]  38.11K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2024-03-04 19:52:15 (20.0 MB/s) - ‘state_of_the_union.txt.1’ saved [39027/39027]\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/hwchase17/langchain/v0.0.200/docs/modules/state_of_the_union.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1906b61-e7ec-46c0-91d6-198279265e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "2024-03-05 00:54:00 | INFO | stdout | INFO:     127.0.0.1:58156 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:00 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:00 | INFO | stdout | INFO:     127.0.0.1:58162 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:00 | INFO | stdout | INFO:     127.0.0.1:51452 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:00 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [1.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:00 | INFO | stdout | INFO:     127.0.0.1:58174 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:51468 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [2.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:58186 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:51476 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [3.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:58198 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:51486 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [4.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:58204 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:51500 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [5.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:58212 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:51506 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:01 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [6.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:01 | INFO | stdout | INFO:     127.0.0.1:58214 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:02 | INFO | stdout | INFO:     127.0.0.1:51520 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:02 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [7.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:02 | INFO | stdout | INFO:     127.0.0.1:58222 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:02 | INFO | stdout | INFO:     127.0.0.1:51528 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:02 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [8.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:02 | INFO | stdout | INFO:     127.0.0.1:58234 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:02 | INFO | stdout | INFO:     127.0.0.1:51540 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:02 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [9.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:02 | INFO | stdout | INFO:     127.0.0.1:58242 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:51544 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [10.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:58254 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:51552 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:39058 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:58264 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [11.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:58270 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who is the speaker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:51554 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:39058 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:58278 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [12.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:58292 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:51564 - \"POST /worker_get_conv_template HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:51576 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:03 | INFO | stdout | INFO:     127.0.0.1:51584 - \"POST /count_token HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:51596 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:39066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:58308 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [13.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:58318 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:51604 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:39058 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:58326 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [14.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:58336 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:51610 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:05 | INFO | stdout | INFO:     127.0.0.1:51622 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The speaker is Nancy Pelosi, the Speaker of the House of Representatives in the United States.\n",
      "Query: What did the president say about Ketanji Brown Jackson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:51634 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:39066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:37156 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [15.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:37162 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:38506 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:39058 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:37166 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [16.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:37172 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:38512 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:10 | INFO | stdout | INFO:     127.0.0.1:38524 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The President, Ketanji Brown Jackson's appointment to the Supreme Court as the first ever African American woman to appear on the Supreme Court in American history. He called it a moment of history and a milestone for the country. The appointment was also presented as a sign of the country's progress towards equality and adherence to the founding principles of the United States.\n",
      "Query: What are the threats to America\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:54:30 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'Trendyol-LLM-7b-chat-v0.1', 'text-embedding-ada-002']. Semaphore: Semaphore(value=4, locked=False). call_ct: 37. worker_id: de683719. \n",
      "2024-03-05 00:54:30 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-05 00:54:30 | INFO | stdout | INFO:     127.0.0.1:51276 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:38534 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:39066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:55060 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:55072 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:41494 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:45134 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:55074 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [1.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:55090 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:41500 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:40 | INFO | stdout | INFO:     127.0.0.1:41506 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The threats to America are significant and diverse. They include:\n",
      "1. Global terrorism: Terrorist groups such as al-Qaeda and ISIS pose a threat to the United States and our allies. They have committed acts of terrorism around the world, including attacks on civilian targets, businesses, and civilian airports.\n",
      "2. Cyber attacks: The growing threat of cyber attacks includes hacking, phishing, and other attacks on critical infrastructure, financial systems, and private companies. These attacks pose risks to national security, economic stability, and public confidence in our systems.\n",
      "3. Coronavirus pandemic: COVID-19 has caused severe health and economic challenges. It has caused significant deaths and disturbances, disrupted education and economic activity, and resulted in a global economic crisis.\n",
      "4. Political divisions: The increasing political divisions in the United States pose a threat to our stability and unity. It has led to a rise in partisanship, polarization, and even violence.\n",
      "5. Globalization: The global economy and the international system are facing significant changes. These changes pose risk to stability, security, and economic stability in the United States and around the world.\n",
      "6. Natural disasters: Increasingly extreme weather events, such as floods, extremely hot weather events, and acquuarnental disasters, pose risks to human health, economic activity, and the environment.\n",
      "7. Nuclear threat: The threat of nuclear weapons and nuclear weapons policy continues to exist. Nuclear weapons pose risks to human health, human life, and the environment. They also pose risks to regional stability and the global economy.\n",
      "8. Iran: The United States' recent negative actions towards Iran, including the withdrawal from the nuclear deal and the re-imposition of sanctions, have led to significant tensions between the United States and Iran, which is a major regional power in the Middle East.\n",
      "9. Healthcare costs: The rising costs of healthcare and the lack of shared responsibility among citizens and employers have led to concerns about affordable healthcare and prertentive medical care.\n",
      "10. Foreign policy: The United States' foreign policy has faced significant challenges, including regional conflicts and transational conflicts. The United States' approach to international organizations, such as the United Nations, has led to conflicts and disagreements with our international partners.\n",
      "Query: Who are mentioned in the speech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:41516 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:39066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:56602 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [2.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:56612 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:46660 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:32774 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:56616 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [3.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:56628 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:46670 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:49 | INFO | stdout | INFO:     127.0.0.1:46678 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: In the speech, there are several individuals mentioned who are important to President Zelenskyy and the Ukrainian people. They are:\n",
      "1. President Zelenskyy\n",
      "2. First Lady Olena Zelenska\n",
      "3. Deputy Prime Minister Mykhailo Fedorov\n",
      "4. Chairman of the National Güvenlik & Defense Council Oleksii Reznikov\n",
      "5. Minister of Defense Oleksii Reznikov\n",
      "6. President of the National Bank of Ukraine Vadym Boychenko\n",
      "7. President of the National Energy Company Nuclear Energy Company\n",
      "8. President of the National Rail Transportation Company Ukrtransnational\n",
      "9. President of the National Telecom Company Ukrtelecom\n",
      "10. President of the National Atomic Energy Corporation Energoatom\n",
      "Query: Who is the vice president\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:46686 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:39066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:56642 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [4.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:56650 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:46692 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:32774 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:56660 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [5.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:56672 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:46696 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:52 | INFO | stdout | INFO:     127.0.0.1:46704 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The current president of the United States is Joe Biden. The current president of the United States is Joe Biden. The current president of the United States is Joe Biden.\n",
      "Query: How many projects were announced\n",
      "Answer: Over 400 projects have been announced in the past year. These projects are expected to create or retain over 750,000 jobs and save taxpayers on trillions of dollars.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:46714 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:39066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "loader = TextLoader(\"state_of_the_union.txt\")\n",
    "index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "questions = [\n",
    "    \"Who is the speaker\",\n",
    "    \"What did the president say about Ketanji Brown Jackson\",\n",
    "    \"What are the threats to America\",\n",
    "    \"Who are mentioned in the speech\",\n",
    "    \"Who is the vice president\",\n",
    "    \"How many projects were announced\",\n",
    "]\n",
    "\n",
    "for query in questions:\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Answer:\", index.query(query, llm=llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aef680fc-40cf-4274-82f9-7f963b44c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:56674 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:54 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [6.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:56684 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:46724 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:32774 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:56692 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:54 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [7.0], ret: http://localhost:21002\n",
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:56700 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:46730 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:54 | INFO | stdout | INFO:     127.0.0.1:46746 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: San Diego, California, United States. It is located in the western part of the state, on the Pacific Coast.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:54:56 | INFO | stdout | INFO:     127.0.0.1:46748 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-05 00:54:56 | INFO | stdout | INFO:     127.0.0.1:39066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", index.query(\"Where is San Diego?\", llm=llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d71c08b1-7718-43e5-8cf0-5e5ae2508048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 20:06:17 | INFO | stdout | INFO:     127.0.0.1:41920 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:17 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-04 20:06:17 | INFO | stdout | INFO:     127.0.0.1:41930 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:17 | INFO | stdout | INFO:     127.0.0.1:43510 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:17 | INFO | stdout | INFO:     127.0.0.1:48094 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:17 | INFO | stdout | INFO:     127.0.0.1:41936 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:17 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [1.0], ret: http://localhost:21002\n",
      "2024-03-04 20:06:17 | INFO | stdout | INFO:     127.0.0.1:41942 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:17 | INFO | stdout | INFO:     127.0.0.1:43514 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:17 | INFO | stdout | INFO:     127.0.0.1:43518 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Here's a plan to get to San Diego from St. George Utah. If you leave at 21:00, you can reach San Diego by 00:00 AM. It's a 4-hour drive, which means that you'd arrive at 0.0:00 AM.\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 20:06:21 | INFO | stdout | INFO:     127.0.0.1:43528 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:21 | INFO | stdout | INFO:     127.0.0.1:48104 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:06:49 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 39. worker_id: 69061595. \n",
      "2024-03-04 20:06:49 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:06:49 | INFO | stdout | INFO:     127.0.0.1:52762 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", index.query(\"I want to go to San Diego from St. George Utah give me a plan\", llm=llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "672120f7-3c1a-4a4a-8f61-13a4be4cb861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 20:08:50 | INFO | stdout | INFO:     127.0.0.1:41298 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:08:50 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [0.0], ret: http://localhost:21002\n",
      "2024-03-04 20:08:50 | INFO | stdout | INFO:     127.0.0.1:41312 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:08:50 | INFO | stdout | INFO:     127.0.0.1:52280 - \"POST /worker_get_embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:08:50 | INFO | stdout | INFO:     127.0.0.1:40064 - \"POST /v1/embeddings HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:08:50 | INFO | stdout | INFO:     127.0.0.1:41324 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:08:50 | INFO | controller | names: ['http://localhost:21002'], queue_lens: [1.0], ret: http://localhost:21002\n",
      "2024-03-04 20:08:50 | INFO | stdout | INFO:     127.0.0.1:41336 - \"POST /get_worker_address HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:08:50 | INFO | stdout | INFO:     127.0.0.1:52290 - \"POST /model_details HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:08:50 | INFO | stdout | INFO:     127.0.0.1:52296 - \"POST /count_token HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Narendra Modi is an Indian politician and the current Prime Minister of India. He was born in Gujarat, India in 1947 and started his career in business. In 2015, he became the leader of the Bhartiya Janata Party (BJP), which is a right-wing political party in India. In 2018, he was elected as the Prime Minister and he has served in this pozisyon since then. Modi has been known for his pro-business policies and economic reforms, as well as his efforts to improve public services and reduce corruption in India. He is considered a popular leader in India and has a significant political influence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 20:08:58 | INFO | stdout | INFO:     127.0.0.1:52300 - \"POST /worker_generate HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:08:58 | INFO | stdout | INFO:     127.0.0.1:40066 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:09:04 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:09:04 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:09:04 | INFO | stdout | INFO:     127.0.0.1:40102 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:09:49 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:09:49 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:09:49 | INFO | stdout | INFO:     127.0.0.1:36498 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:10:34 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:10:34 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:10:34 | INFO | stdout | INFO:     127.0.0.1:43244 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:10:48 | INFO | stdout | INFO:     127.0.0.1:47896 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:10:49 | INFO | stdout | INFO:     127.0.0.1:47896 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:10:57 | INFO | controller | Register a new worker: http://localhost:21002\n",
      "2024-03-04 20:10:57 | INFO | stdout | INFO:     127.0.0.1:41780 - \"POST /worker_get_status HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:10:57 | INFO | controller | Register done: http://localhost:21002, {'model_names': ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002'], 'speed': 1, 'queue_length': 0}\n",
      "2024-03-04 20:10:57 | INFO | stdout | INFO:     127.0.0.1:59136 - \"POST /refresh_all_workers HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:10:57 | INFO | stdout | INFO:     127.0.0.1:59148 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:10:57 | INFO | stdout | INFO:     127.0.0.1:47912 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:11:19 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:11:19 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:11:19 | INFO | stdout | INFO:     127.0.0.1:33920 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:11:48 | INFO | controller | Register a new worker: http://localhost:21002\n",
      "2024-03-04 20:11:48 | INFO | stdout | INFO:     127.0.0.1:44526 - \"POST /worker_get_status HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:11:48 | INFO | controller | Register done: http://localhost:21002, {'model_names': ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002'], 'speed': 1, 'queue_length': 0}\n",
      "2024-03-04 20:11:48 | INFO | stdout | INFO:     127.0.0.1:60038 - \"POST /refresh_all_workers HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:11:48 | INFO | stdout | INFO:     127.0.0.1:60046 - \"POST /list_models HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:11:48 | INFO | stdout | INFO:     127.0.0.1:51654 - \"GET /v1/models HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:12:04 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:12:04 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:12:04 | INFO | stdout | INFO:     127.0.0.1:43884 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:12:49 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:12:49 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:12:49 | INFO | stdout | INFO:     127.0.0.1:49442 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:13:34 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:13:34 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:13:34 | INFO | stdout | INFO:     127.0.0.1:33858 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:14:19 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:14:19 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:14:19 | INFO | stdout | INFO:     127.0.0.1:33074 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:15:04 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:15:04 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:15:04 | INFO | stdout | INFO:     127.0.0.1:34978 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n",
      "2024-03-04 20:15:49 | INFO | model_worker | Send heart beat. Models: ['gpt-3.5-turbo', 'text-davinci-003', 'text-embedding-ada-002']. Semaphore: Semaphore(value=5, locked=False). call_ct: 45. worker_id: 69061595. \n",
      "2024-03-04 20:15:49 | INFO | controller | Receive heart beat. http://localhost:21002\n",
      "2024-03-04 20:15:49 | INFO | stdout | INFO:     127.0.0.1:45318 - \"POST /receive_heart_beat HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", index.query(\"Who is narendra modi?\", llm=llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e930c-a9f3-4171-a4e3-00903f651eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
